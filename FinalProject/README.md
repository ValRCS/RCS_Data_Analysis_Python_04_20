# Final Project

 You should submit a notebook or even a full github repo

## Your code should

Do at least **one** of the following:

1. Gathers data (this includes web scraping)
2. Cleans, and rearranges data
 * combines 2 or more sources (for example combines view from SQL select with some JSON)
3. Explores data
4. Visualizes data
5. Builds a model
6. Tests the model(how good the predictions are)
7. Presents full working pipeline in as friendly a form as possible

In real life you'd have to do a bit of all of the above

## Goal

Build partial / full data analysis pipeline

* Define the problem - desired end result
* Gather the raw data (web scraping, files, databases, etc)
* Process (clean, combine, transform) the data
* Explore (gather statistics, basic visualizations)
* Analysis (apply models, make predictions)
* Reports and Visual Results

At the class make a short (5-10min) presentation on what worked and what did not.

If you made a Jupyter notebook, simply show the notebook, no need for extra presentation. :)

You can use other tools for final reports (such as PowerBI, Tableau etc) but there is no requirement.

Ideally, you would put the notebook on your public Github account and submit the link to repository.

For sensitive data, keep in on your computer and run notebook from your computer locally. Simply submit the project description then

I really like to see lots of data cleaning and moving as that is what happens the most.
